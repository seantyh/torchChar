{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(\"DEBUG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src\\torchChar\\prepare_data.py:9: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import torchChar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:load train_examples/char_examples_Ming.pkl\n",
      "INFO:root:load train_examples/char_examples_Kai.pkl\n",
      "INFO:root:load train_examples/char_examples_Yen.pkl\n",
      "INFO:root:load train_examples/char_examples_FangSong.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2355c1d634754e5f8c63247452b90d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='converting features', max=1.0, style=Prâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dev_dataset = torchChar.load_and_cache_features(\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4733"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dev_dataset, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitmaps = batch[0]\n",
    "radicals = batch[1]\n",
    "consonants = batch[2]\n",
    "vowels = batch[3]\n",
    "tones = batch[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(bitmaps.shape[-2:]) == (64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20480"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "80*16*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "nradicals = len(torchChar.Radicals())\n",
    "ntones = len(torchChar.Tones())\n",
    "nconsonants = len(torchChar.Consonants())\n",
    "nvowels = len(torchChar.Vowels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(radicals.radicals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(1, 20, 3, padding=1)\n",
    "pool1 = nn.MaxPool2d(2, 2)\n",
    "conv2 = nn.Conv2d(20, 40, 5, padding=2)\n",
    "pool2 = nn.MaxPool2d(2, 2)\n",
    "conv3 = nn.Conv2d(40, 80, 5, padding=2)\n",
    "\n",
    "fc1 = nn.Linear(80*16*16, 1000)\n",
    "fc2 = nn.Linear(1000, 500)\n",
    "fc3 = nn.Linear(500, 200)\n",
    "fc_radicals = nn.Linear(500, nradicals)\n",
    "fc_tones = nn.Linear(200, ntones)\n",
    "fc_consonants = nn.Linear(200, nconsonants)\n",
    "fc_vowels = nn.Linear(200, nvowels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 shape: torch.Size([3, 20, 64, 64])\n",
      "pool1 shape: torch.Size([3, 20, 32, 32])\n",
      "conv2 shape: torch.Size([3, 40, 32, 32])\n",
      "pool2 shape: torch.Size([3, 40, 16, 16])\n",
      "conv3 shape: torch.Size([3, 80, 16, 16])\n",
      "v1 shape: torch.Size([3, 500])\n",
      "o_radicals shape: torch.Size([3, 214])\n",
      "v2 shape: torch.Size([3, 200])\n",
      "o_tones shape: torch.Size([3, 5])\n",
      "o_consonants shape: torch.Size([3, 21])\n",
      "o_vowels shape: torch.Size([3, 16])\n"
     ]
    }
   ],
   "source": [
    "x = bitmaps.unsqueeze(1).float()\n",
    "h = conv1(x)\n",
    "print(\"conv1 shape: \" + str(h.shape))\n",
    "h = F.relu(pool1(h))\n",
    "print(\"pool1 shape: \" + str(h.shape))\n",
    "h = conv2(h)\n",
    "print(\"conv2 shape: \" + str(h.shape))\n",
    "h = F.relu(pool2(h))\n",
    "print(\"pool2 shape: \" + str(h.shape))\n",
    "h = conv3(h)\n",
    "print(\"conv3 shape: \" + str(h.shape))\n",
    "\n",
    "v1 = fc1(F.relu(h.view(-1, 80*16*16)))\n",
    "v1 = fc2(F.relu(v1))\n",
    "\n",
    "print(\"v1 shape: \" + str(v1.shape))\n",
    "o_radicals = fc_radicals(F.relu(v1))\n",
    "print(\"o_radicals shape: \" + str(o_radicals.shape))\n",
    "\n",
    "v2 = fc3(F.relu(v1))\n",
    "print(\"v2 shape: \" + str(v2.shape))\n",
    "o_tones = fc_tones(F.relu(v2))\n",
    "print(\"o_tones shape: \" + str(o_tones.shape))\n",
    "o_consonants = fc_consonants(F.relu(v2))\n",
    "print(\"o_consonants shape: \" + str(o_consonants.shape))\n",
    "o_vowels = fc_vowels(F.relu(v2))\n",
    "print(\"o_vowels shape: \" + str(o_vowels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 11664])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.view(3, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
